@article{ayub2020c,
abstract = {For many applications, robots will need to be incrementally trained to recognize the specific objects needed for an application. This paper presents a practical system for incrementally training a robot to recognize different object categories using only a small set of visual examples provided by a human. The paper uses a recently developed state-of-the-art method for few-shot incremental learning of objects. After learning the object classes incrementally, the robot performs a table cleaning task organizing objects into categories specified by the human. We also demonstrate the system's ability to learn arrangements of objects and predict missing or incorrectly placed objects. Experimental evaluations demonstrate that our approach achieves nearly the same performance as a system trained with all examples at one time (batch training), which constitutes a theoretical upper bound.},
archivePrefix = {arXiv},
arxivId = {2008.00819},
author = {Ayub, Ali and Wagner, Alan R.},
eprint = {2008.00819},
journal = {arXiv},
keywords = {catastrophic forgetting,continual learning,few-shot incremenatl learning,robotics},
month = {jul},
title = {{Tell me what this is: Few-Shot Incremental Object Learning by a Robot}},
url = {http://arxiv.org/abs/2008.00819},
year = {2020}
}
@article{zhao2020a,
abstract = {As a challenging problem in machine learning, few-shot class-incremental learning asynchronously learns a sequence of tasks, acquiring the new knowledge from new tasks (with limited new samples) while keeping the learned knowledge from previous tasks (with old samples discarded). In general, existing approaches resort to one unified feature space for balancing old-knowledge preserving and new-knowledge adaptation. With a limited embedding capacity of feature representation, the unified feature space often makes the learner suffer from semantic drift or overfitting as the number of tasks increases. With this motivation, we propose a novel few-shot class-incremental learning pipeline based on a composite representation space, which makes old-knowledge preserving and new-knowledge adaptation mutually compatible by feature space composition (enlarging the embedding capacity). The composite representation space is generated by integrating two space components (i.e. stable base knowledge space and dynamic lifelong-learning knowledge space) in terms of distance metric construction. With the composite feature space, our method performs remarkably well on the CUB200 and CIFAR100 datasets, outperforming the state-of-the-art algorithms by 10.58{\%} and 14.65{\%} respectively.},
author = {Zhao, H. and Fu, Y. and Li, X. and Li, S. and Omar, B. and Li, X.},
journal = {arXiv},
keywords = {[cifar],[cubs]},
mendeley-tags = {[cifar],[cubs]},
title = {{Few-Shot Class-Incremental Learning via Feature Space Composition}},
url = {https://arxiv.org/abs/2006.15524},
year = {2020}
}
@inproceedings{tao2020a,
abstract = {The ability to incrementally learn new classes is crucial to the development of real-world artificial intelligence systems. In this paper, we focus on a challenging but practical few-shot class-incremental learning (FSCIL) problem. FSCIL requires CNN models to incrementally learn new classes from very few labelled samples, without forgetting the previously learned ones. To address this problem, we represent the knowledge using a neural gas (NG) network, which can learn and preserve the topology of the feature manifold formed by different classes. On this basis, we propose the TOpology-Preserving knowledge InCrementer (TOPIC) framework. TOPIC mitigates the forgetting of the old classes by stabilizing NG's topology and improves the representation learning for few-shot new classes by growing and adapting NG to new training samples. Comprehensive experimental results demonstrate that our proposed method significantly outperforms other state-of-the-art class-incremental learning methods on CIFAR100, miniImageNet, and CUB200 datasets.},
author = {Tao, X. and X., Hong and Chang, X. and Dong, S. and Wei, X. and Gong, Y.},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
keywords = {[cifar]},
mendeley-tags = {[cifar]},
title = {{Few-Shot Class-Incremental Learning}},
url = {https://arxiv.org/abs/2004.10956},
year = {2020}
}
@inproceedings{ayub2020a,
abstract = {Incremental learning attempts to develop a classifier which learns continuously from a stream of data segregated into different classes. Deep learning approaches suffer from catastrophic forgetting when learning classes incrementally, while most incremental learning approaches require a large amount of training data per class. We examine the problem of incremental learning using only a few training examples, referred to as Few-Shot Incremental Learning (FSIL). To solve this problem, we propose a novel approach inspired by the concept learning model of the hippocampus and the neocortex that represents each image class as centroids and does not suffer from catastrophic forgetting. We evaluate our approach on three class-incremental learning benchmarks: Caltech-101, CUBS-200-2011 and CIFAR-100 for incremental and few-shot incremental learning and show that our approach achieves state-of-the-art results in terms of classification accuracy over all learned classes.},
author = {Ayub, A. and Wagner, A. R.},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {[cifar],[cubs],[dual],catastrophic forgetting,cognitively-inspired learning,continual learning},
mendeley-tags = {[cifar],[cubs],[dual]},
title = {{Cognitively-Inspired Model for Incremental Learning Using a Few Examples}},
url = {https://openaccess.thecvf.com/content{\_}CVPRW{\_}2020/html/w15/Ayub{\_}Cognitively-Inspired{\_}Model{\_}for{\_}Incremental{\_}Learning{\_}Using{\_}a{\_}Few{\_}Examples{\_}CVPRW{\_}2020{\_}paper.html},
year = {2020}
}
@article{Antoniou2020a,
abstract = {Both few-shot and continual learning have seen substantial progress in the last years due to the introduction of proper benchmarks. That being said, the field has still to frame a suite of benchmarks for the highly desirable setting of continual few-shot learning, where the learner is presented a number of few-shot tasks, one after the other, and then asked to perform well on a validation set stemming from all previously seen tasks. Continual few-shot learning has a small computational footprint and is thus an excellent setting for efficient investigation and experimentation. In this paper we first define a theoretical framework for continual few-shot learning, taking into account recent literature, then we propose a range of flexible benchmarks that unify the evaluation criteria and allows exploring the problem from multiple perspectives. As part of the benchmark, we introduce a compact variant of ImageNet, called SlimageNet64, which retains all original 1000 classes but only contains 200 instances of each one (a total of 200K data-points) downscaled to 64 x 64 pixels. We provide baselines for the proposed benchmarks using a number of popular few-shot learning algorithms, as a result, exposing previously unknown strengths and weaknesses of those algorithms in continual and data-limited settings.},
archivePrefix = {arXiv},
arxivId = {2004.11967},
author = {Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos},
eprint = {2004.11967},
journal = {arXiv},
keywords = {[imagenet]},
mendeley-tags = {[imagenet]},
month = {apr},
title = {{Defining Benchmarks for Continual Few-Shot Learning}},
url = {http://arxiv.org/abs/2004.11967},
year = {2020}
}
