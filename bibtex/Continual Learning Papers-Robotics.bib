@inproceedings{dehghan2019a,
abstract = {This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new tools and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are a) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, b) an intuitive user interface for specifying 3D motion task associated with the new object, c) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.},
author = {Dehghan, M. and Zhang, Z. and Siam, M. and Jin, J. and Petrich, L. and Jagersand, M.},
booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
title = {{Online Object and Task Learning via Human Robot Interaction}},
url = {https://arxiv.org/abs/1809.08722},
year = {2019}
}
@incollection{thrun1995b,
abstract = {Designing robots that learn by themselves to perform complex real-world tasks is a still-open challenge for the field of robotics and artificial intelligence. This chapter presents the robot learning problem as a lifelong problem, in which a robot faces a collection of tasks over its entire lifetime. Such a scenario provides the opportunity to gather general-purpose knowledge that transfers across tasks. The chapter illustrates a learning mechanism, explanation-based neural-network learning, that transfers knowledge between related tasks via neural-network action models. The learning approach is illustrated using a mobile robot, equipped with visual, ultrasonic, and laser sensors. In less than 10 minutes of operation time, the robot is able to learn to navigate to a marked target object in a natural office environment.},
address = {Amsterdam},
author = {Thrun, Sebastian},
booktitle = {Intelligent Robots and Systems},
doi = {10.1016/B978-044482250-5/50015-3},
editor = {Graefe, Volker},
isbn = {978-0-444-82250-5},
language = {en},
month = {jan},
pages = {201--214},
publisher = {Elsevier Science B.V.},
title = {{A Lifelong Learning Perspective for Mobile Robot Control}},
url = {http://www.sciencedirect.com/science/article/pii/B9780444822505500153},
year = {1995}
}
@inproceedings{Mitchell1993a,
abstract = {How can artificial neural nets generalize better from fewer examples? In order to generalize successfully, neural network learning methods typically require large training data sets. We introduce a neural network learning method that generalizes rationally from many fewer data points, relying instead on prior knowledge encoded in previously learned neural networks. For example, in robot control learning tasks reported here, previously learned networks that model the effects of robot actions are used to guide subsequent learning of robot control functions. For each observed training example of the target function (e.g. the robot control policy), the learner explains the observed example in terms of its prior knowledge, then analyzes this explanation to infer additional information about the shape, or slope, of the target function. This shape knowledge is used to bias generalization when learning the target function. Results are presented applying this approach to a simulated robot task based on reinforcement learning.},
author = {Mitchell, Tom M and Thrun, Sebastian B},
booktitle = {Advances in Neural Information Processing Systems 5},
file = {::},
title = {{Explanation-Based Neural Network Learning for Robot Control}},
year = {1993}
}
@article{Wong2016a,
abstract = {Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.},
archivePrefix = {arXiv},
arxivId = {1611.00201},
author = {Wong, Jay M},
eprint = {1611.00201},
journal = {arXiv},
keywords = {autonomy,cognition,deep learning,lifelong learning,robotics},
month = {nov},
title = {{Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics}},
url = {http://arxiv.org/abs/1611.00201},
year = {2016}
}
@article{Lesort2020c,
abstract = {Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective change through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. CL can be seen as an online learning where knowledge fusion needs to take place in order to learn from streams of data presented sequentially in time. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier. We put light on continual learning in the context of robotics to create connections between fields and normalize approaches.},
annote = {Overview of a CL framework for applications in robotic, together with discussion of existing CL strategies and techniques.},
author = {Lesort, Timoth{\'{e}}e and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and D{\'{i}}az-Rodr{\'{i}}guez, Natalia},
doi = {10.1016/j.inffus.2019.12.004},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {Catastrophic Forgetting,Continual Learning,Deep Learning,Lifelong Learning,Reinforcement Learning,Robotics,[framework]},
language = {en},
mendeley-tags = {[framework]},
month = {jun},
pages = {52--68},
shorttitle = {Continual learning for robotics},
title = {{Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges}},
url = {http://www.sciencedirect.com/science/article/pii/S1566253519307377},
volume = {58},
year = {2020}
}
