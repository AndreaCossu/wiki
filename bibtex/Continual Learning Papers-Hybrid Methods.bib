@inproceedings{Hou2018a,
abstract = {Lifelong learning aims at adapting a learned model to new tasks while retaining the knowledge gained earlier. A key challenge for lifelong learning is how to strike a balance between the preservation on old tasks and the adaptation to a new one within a given model. Approaches that combine both objectives in training have been explored in previous works. Yet the performance still suffers from considerable degradation in a long sequence of tasks. In this work, we propose a novel approach to lifelong learning, which tries to seek a better balance between preservation and adaptation via two techniques: Distillation and Retrospection. Specifically, the target model adapts to the new task by knowledge distillation from an intermediate expert, while the previous knowledge is more effectively preserved by caching a small subset of data for old tasks. The combination of Distillation and Retrospection leads to a more gentle learning curve for the target model, and extensive experiments demonstrate that our approach can bring consistent improvements on both old and new tasks.},
author = {Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
booktitle = {ECCV},
doi = {10.1007/978-3-030-01219-9_27},
isbn = {9783030012182},
issn = {16113349},
keywords = {Knowledge distillation,Lifelong learning,Retrospection,[imagenet],[vision]},
mendeley-tags = {[imagenet],[vision]},
title = {{Lifelong Learning via Progressive Distillation and Retrospection}},
url = {http://link.springer.com/10.1007/978-3-030-01219-9{\_}27},
year = {2018}
}
@article{Du2019a,
abstract = {There is an increasing need of continual learning in dynamic systems, such as the self-driving vehicle, the surveillance drone, and the robotic system. Such a system requires learning from the data stream, training the model to preserve previous information and adapt to a new task, and generating a single-headed vector for future inference. Different from previous approaches with dynamic structures, this work focuses on a single network and model segmentation to prevent catastrophic forgetting. Leveraging the redundant capacity of a single network, model parameters for each task are separated into two groups: one important group which is frozen to preserve current knowledge, and secondary group to be saved (not pruned) for a future learning. A fixed-size memory containing a small amount of previously seen data is further adopted to assist the training. Without additional regularization, the simple yet effective approach of PST successfully incorporates multiple tasks and achieves the state-of-the-art accuracy in the single-head evaluation on CIFAR-10 and CIFAR-100 datasets. Moreover, the segmented training significantly improves computation efficiency in continual learning.},
archivePrefix = {arXiv},
arxivId = {1905.11550},
author = {Du, Xiaocong and Charan, Gouranga and Liu, Frank and Cao, Yu},
doi = {10.1109/ICMLA.2019.00267},
eprint = {1905.11550},
isbn = {9781728145501},
journal = {arXiv},
keywords = {[cifar]},
mendeley-tags = {[cifar]},
month = {may},
number = {2},
pages = {1629--1636},
title = {{Single-Net Continual Learning with Progressive Segmented Training (PST)}},
url = {http://arxiv.org/abs/1905.11550},
year = {2019}
}
@inproceedings{lomonaco2020a,
abstract = {Robotic vision is a field where continual learning can play a significant role. An embodied agent operating in a complex environment subject to frequent and unpredictable changes is required to learn and adapt continuously. In the context of object recognition, for example, a robot should be able to learn (without forgetting) objects of never before seen classes as well as improving its recognition capabilities as new instances of already known classes are discovered. Ideally, continual learning should be triggered by the availability of short videos of single objects and performed on-line on on-board hardware with fine-grained updates. In this paper, we introduce a novel continual learning protocol based on the CORe50 benchmark and propose two rehearsal-free continual learning techniques, CWR* and AR1*, that can learn effectively even in the challenging case of nearly 400 small non-i.i.d. incremental batches. In particular, our experiments show that AR1* can outperform other state-of-the-art rehearsal-free techniques by more than 15{\%} accuracy in some cases, with a very light and constant computational and memory overhead across training batches.},
author = {Lomonaco, Vincenzo and Maltoni, Davide and Pellegrini, Lorenzo},
booktitle = {CVPR Workshop on Continual Learning for Computer Vision},
file = {:home/andrea/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lomonaco, Maltoni, Pellegrini - 2020 - Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches.pdf:pdf},
keywords = {[core50]},
mendeley-tags = {[core50]},
pages = {246--247},
title = {{Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches}},
url = {https://openaccess.thecvf.com/content{\_}CVPRW{\_}2020/html/w15/Lomonaco{\_}Rehearsal-Free{\_}Continual{\_}Learning{\_}Over{\_}Small{\_}Non-I.I.D.{\_}Batches{\_}CVPRW{\_}2020{\_}paper.html},
year = {2020}
}
@article{Wang2019a,
abstract = {Continual learning consists in incrementally training a model on a sequence of datasets and testing on the union of all datasets. In this paper, we examine continual learning for the problem of sound classification, in which we wish to refine already trained models to learn new sound classes. In practice one does not want to maintain all past training data and retrain from scratch, but naively updating a model with new data(sets) results in a degradation of already learned tasks, which is referred to as "catastrophic forgetting." We develop a generative replay procedure for generating training audio spectrogram data, in place of keeping older training datasets. We show that by incrementally refining a classifier with generative replay a generator that is 4{\%} of the size of all previous training data matches the performance of refining the classifier keeping 20{\%} of all previous training data. We thus conclude that we can extend a trained sound classifier to learn new classes without having to keep previously used datasets.},
annote = {arXiv: 1906.00654},
author = {Wang, Zhepei and Subakan, Cem and Tzinis, Efthymios and Smaragdis, Paris and Charlin, Laurent},
journal = {arXiv},
keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio,Statistics - Machine Learning,[audio],audio,sequence,sequences,time series},
mendeley-tags = {[audio]},
month = {jun},
title = {{Continual Learning of New Sound Classes using Generative Replay}},
url = {http://arxiv.org/abs/1906.00654},
year = {2019}
}
@article{Maltoni2018a,
abstract = {It was recently shown that architectural, regularization and rehearsal strategies can be used to train deep models sequentially on a number of disjoint tasks without forgetting previously acquired knowledge. However, these strategies are still unsatisfactory if the tasks are not disjoint but constitute a single incremental task (e.g., class-incremental learning). In this paper we point out the differences between multi-task and single-incremental-task scenarios and show that well-known approaches such as LWF, EWC and SI are not ideal for incremental task scenarios. A new approach, denoted as AR1, combining architectural and regularization strategies is then speciÔ¨Åcally proposed. AR1 overhead (in terms of memory and computation) is very small thus making it suitable for online learning. When tested on CORe50 and iCIFAR-100, AR1 outperformed existing regularization strategies by a good margin.},
annote = {Comment: 26 pages, 13 figures; v3: major revision (e.g. added Sec. 4.4), several typos and minor mistakes corrected
arXiv: 1806.08568},
author = {Maltoni, Davide and Lomonaco, Vincenzo},
journal = {arXiv},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Continuous learning,Deep learning,Incremental class learning,Lifelong learning,Object recognition,Single-incremental-task,Statistics - Machine Learning,[core50],[framework],ewc,incremental task,review},
language = {en},
mendeley-tags = {[core50],[framework]},
month = {jun},
title = {{Continuous Learning in Single-Incremental-Task Scenarios}},
url = {http://arxiv.org/abs/1806.08568},
year = {2018}
}
@inproceedings{Schwarz2018a,
abstract = {We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to ...},
author = {Schwarz, Jonathan and Czarnecki, Wojciech and Luketina, Jelena and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
booktitle = {International Conference on Machine Learning},
keywords = {[vision],ewc,normalized ewc,online ewc},
language = {en},
mendeley-tags = {[vision]},
month = {jul},
pages = {4528--4537},
shorttitle = {Progress {\&} Compress},
title = {{Progress {\&} Compress: A scalable framework for continual learning}},
url = {http://proceedings.mlr.press/v80/schwarz18a.html},
year = {2018}
}
