Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{French1997a,
abstract = {In order to solve the “sensitivity-stability” problem — and its immediate correlate, the problem of sequential learning — it is crucial to develop connectionist architectures that are simultaneously sensitive to, but not excessively disrupted by, new input. French (1992) suggested that to alleviate a particularly severe form of this disruption, catastrophic forgetting, it was necessary for networks to dynamically separate their internal representations during learning. McClelland, McNaughton, {\&} O'Reilly (1995) went even further. They suggested that nature's way of implementing this obligatory separation was the evolution of two separate areas of the brain, the hippocampus and the neocortex. In keeping with this idea of radical separation, a “pseudo-recurrent” memory model is presented here that partitions a connectionist network into two functionally distinct, but continually interacting areas. One area serves as a final-storage area for representations; the other is an early-processing area where new representations are first learned by the system. The final-storage area continually supplies internally generated patterns (pseudopatterns, Robins (1995)), which are approximations of its content, to the early-processing area, where they are interleaved with the new patterns to be learned. Transfer of the new learning is done either by weight-copying from the early-processing area to the final-storage area or by pseudopattern transfer. A number of experiments are presented that demonstrate the effectiveness of this approach, allowing, in particular, effective sequential learning with gradual forgetting in the presence of new input. Finally, it is shown that the two interacting areas automatically produce representational compaction and it is suggested that similar representational streamlining may exist in the brain.},
annote = {In this seminal paper the author introduces many different forms of rehearsal in order to mitigate the catastrophic forgetting phenomenon},
author = {French, Robert},
doi = {10.1080/095400997116595},
issn = {0954-0091, 1360-0494},
journal = {Connection Science},
keywords = {Catastrophic Interference,Dual Memory,Keywords: Pseudopatterns,Semi-distributed Representations,Sensitivity-stability Transfer,dilemma,plasticity,stability},
language = {en},
month = {dec},
number = {4},
pages = {353--380},
shorttitle = {Pseudo-recurrent Connectionist Networks},
title = {{Pseudo-recurrent Connectionist Networks: An Approach to the 'Sensitivity-Stability' Dilemma}},
url = {http://www.tandfonline.com/doi/abs/10.1080/095400997116595},
volume = {9},
year = {1997}
}
@inproceedings{French1991a,
abstract = {In connectionist networks, newly-learned information destroys previously-learned information unless the network is continually retrained on the old information. This behavior, known as catastrophic forgetting, is unacceptable both for practical purposes and as a model of mind. This paper advances the claim that catastrophic forgetting is a direct consequence of the overlap of the system's distributed representations and can be reduced by reducing this overlap. A simple algorithm is presented that allows a standard feedforward backpropagation network to develop semi-distributed representations, thereby significantly reducing the problem of catastrophic forgetting. 1 Introduction Catastrophic forgetting is the inability of a neural network to retain old information in the presence of new. New information destroys old unless the old information is continually relearned by the net. McCloskey {\&} Cohen [1990] and Ratcliff [1989] have demonstrated that this is a serious problem with c...},
author = {French, Robert M},
booktitle = {In Proceedings of the 13th Annual Cognitive Science Society Conference},
keywords = {[sparsity],activation sharpening},
mendeley-tags = {[sparsity]},
pages = {173--178},
publisher = {Erlbaum},
title = {{Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionist Networks}},
year = {1991}
}
@article{Ring1997a,
abstract = {Continual learning is the constant development of increasingly complex behaviors; the process of building more complicated skills on top of those already developed. A continual-learning agent should therefore learn incrementally and hierarchically. This paper describes CHILD, an agent capable of Continual, Hierarchical, Incremental Learning and Development. CHILD can quickly solve complicated non-Markovian reinforcement-learning tasks and can then transfer its skills to similar but even more complicated tasks, learning these faster still.},
author = {Ring, Mark B},
doi = {10.1023/A:1007331723572},
issn = {1573-0565},
journal = {Machine Learning},
keywords = {Continual learning,cl,continual learner,definition,hierarchical neural networks,reinforcement learning,sequence learning,transfer},
language = {en},
month = {jul},
number = {1},
pages = {77--104},
shorttitle = {CHILD},
title = {{CHILD: A First Step Towards Continual Learning}},
url = {https://doi.org/10.1023/A:1007331723572},
volume = {28},
year = {1997}
}
@article{Robins1995a,
abstract = {This paper reviews the problem of catastrophic forgetting (the loss or disruption of previously learned information when new information is learned) in neural networks, and explores rehearsal mechanisms (the retraining of some of the previously learned information as the new information is added) as a potential solution. W e replicate some of the experiments described by Ratcliff (1990), including those relating to a simple `recency' based rehearsal regime. W e then develop further rehearsal regimes which are more effective than recency rehearsal. In particular, `sweep rehearsal' is very successful at minimizing catastrophic forgetting. One possible limitation of rehearsal in general, however, is that previously learned information may not be available for retraining. W e describe a solution to this problem, `pseudorehearsal' , a method which provides the advantages of rehearsal without actually requiring any access to the previously learned information (the original training population) itself. We then suggest an interpretation of these rehearsal mechanisms in the context of a function approximation based account of neural network learning. Both rehearsal and pseudorehearsal may have practical applications, allowing new information to be integrated into an existing network with minimum disruption of old inform a tion.},
author = {Robins, Anthony},
doi = {10.1080/09540099550039318},
issn = {0954-0091, 1360-0494},
journal = {Connection Science},
language = {en},
month = {jun},
number = {2},
pages = {123--146},
title = {{Catastrophic Forgetting; Catastrophic Interference; Stability; Plasticity; Rehearsal.}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09540099550039318},
volume = {7},
year = {1995}
}
@inproceedings{Thrun1996a,
author = {Thrun, Sebastian},
booktitle = {Advances in Neural Information Processing Systems 8},
editor = {Touretzky, D S and Mozer, M C and Hasselmo, M E},
keywords = {lifelong,lifelong learning},
pages = {640--646},
publisher = {MIT Press},
title = {{Is Learning The n-th Thing Any Easier Than Learning The First?}},
url = {http://papers.nips.cc/paper/1034-is-learning-the-n-th-thing-any-easier-than-learning-the-first.pdf},
year = {1996}
}
