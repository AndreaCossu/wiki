Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Coop2013a,
abstract = {Catastrophic forgetting (or catastrophic interference) in supervised learning systems is the drastic loss of previously stored information caused by the learning of new information. While substantial work has been published on addressing catastrophic forgetting in memoryless supervised learning systems (e.g. feedforward neural networks), the problem has received limited attention in the context of dynamic systems, particularly recurrent neural networks. In this paper, we introduce a solution for mitigating catastrophic forgetting in RNNs based on enhancing the Fixed Expansion Layer (FEL) neural network which exploits sparse coding of hidden neuron activations. Simulation results on several non-stationary data sets clearly demonstrate the effectiveness of the proposed architecture.},
address = {Dallas, TX, USA},
author = {Coop, Robert and Arel, Itamar},
booktitle = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2013.6707047},
isbn = {978-1-4673-6129-3 978-1-4673-6128-6},
keywords = {fel,mnist,recurrent fel,rnn,sparsity},
language = {en},
mendeley-tags = {mnist,rnn,sparsity},
month = {aug},
pages = {1--7},
publisher = {IEEE},
title = {{Mitigation of catastrophic forgetting in recurrent neural networks using a Fixed Expansion Layer}},
url = {http://ieeexplore.ieee.org/document/6707047/},
year = {2013}
}
@article{Parisi2018a,
abstract = {Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting in which novel sensory experience interferes with existing representations and leads to abrupt decreases in the performance on previously acquired knowledge. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. Therefore, specialized neural network mechanisms are required that adapt to novel sequential experience while preventing disruptive interference with existing representations. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios.},
author = {Parisi, German I and Tani, Jun and Weber, Cornelius and Wermter, Stefan},
doi = {10.3389/fnbot.2018.00078},
issn = {1662-5218},
journal = {Frontiers in Neurorobotics},
keywords = {CLS,Incremental Learning,Lifelong learning,Memory,Self-organizing Network,core50,dual,object recognition systems,som},
language = {English},
mendeley-tags = {core50,dual,som},
title = {{Lifelong Learning of Spatiotemporal Representations With Dual-Memory Recurrent Self-Organization}},
url = {https://www.frontiersin.org/articles/10.3389/fnbot.2018.00078/full},
volume = {12},
year = {2018}
}
@article{Cui2016a,
abstract = {The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.},
annote = {Publisher: MIT Press},
author = {Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff},
doi = {10.1162/NECO_a_00893},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {htm,spiking},
mendeley-tags = {spiking},
month = {sep},
number = {11},
pages = {2474--2504},
title = {{Continuous Online Sequence Learning with an Unsupervised Neural Network Model}},
url = {https://doi.org/10.1162/NECO{\_}a{\_}00893},
volume = {28},
year = {2016}
}
@misc{Ororbia2020a,
abstract = {For energy-efficient computation in specialized neuromorphic hardware, we present the Spiking Neural Coding Network, an instantiation of a family of artificial neural models strongly motivated by the theory of predictive coding. The model, in essence, works by operating in a never-ending process of "guess-and-check", where neurons predict the activity values of one another and then immediately adjust their own activities to make better future predictions. The interactive, iterative nature of our neural system fits well into the continuous time formulation of data sensory stream prediction and, as we show, the model's structure yields a simple, local synaptic update rule, which could be used to complement or replace online spike-timing dependent plasticity. In this article, we experiment with an instantiation of our model that consists of leaky integrate-and-fire units. However, the general framework within which our model is situated can naturally incorporate more complex, formal neurons such as the Hodgkin-Huxley model. Our experimental results in pattern recognition demonstrate the potential of the proposed model when binary spike trains are the primary paradigm for inter-neuron communication. Notably, our model is competitive in terms of classification performance, can conduct online semi-supervised learning, naturally experiences less forgetting when learning from a sequence of tasks, and is more computationally economical and biologically-plausible than popular artificial neural networks.},
annote = {Comment: Revised version of manuscript – includes updated experimental results
arXiv: 1908.08655},
author = {Ororbia, Alexander},
booktitle = {arXiv:1908.08655 [cs, q-bio]},
keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Quantitative Biology - Neurons and Cognition},
month = {jan},
title = {{Spiking Neural Predictive Coding for Continual Learning from Data Streams}},
url = {http://arxiv.org/abs/1908.08655},
year = {2020}
}
@inproceedings{Aljundi2019c,
abstract = {Sequential learning, also called lifelong learning, studies the problem of learning tasks in a sequence with access restricted to only the data of the current task. In this paper we look at a...},
annote = {The authors combine multiple penalizations to (1) induce sparse activations through lateral inhibitions between neurons and to (2) penalize changes in most important weights in order to prevent forgetting.},
author = {Aljundi, Rahaf and Rohrbach, Marcus and Tuytelaars, Tinne},
booktitle = {ICLR},
keywords = {cifar,mnist,sparsity},
mendeley-tags = {cifar,mnist,sparsity},
title = {{Selfless Sequential Learning}},
url = {https://openreview.net/forum?id=Bkxbrn0cYX},
year = {2019}
}
@inproceedings{Coop2012a,
abstract = {In this paper we present the fixed expansion layer (FEL) feedforward neural network designed for balancing plasticity and stability in the presence of non-stationary inputs. Catastrophic interference (or catastrophic forgetting) refers to the drastic loss of previously learned information when a neural network is trained on new or different information. The goal of the FEL network is to reduce the effect of catastrophic interference by augmenting a multilayer perceptron with a layer of sparse neurons with binary activations. We compare the FEL network's performance to that of other algorithms designed to combat the effects of catastrophic interference and demonstrate that the FEL network is able to retain information for significantly longer periods of time with substantially lower computational requirements.},
annote = {ISSN: 1548-3746},
author = {Coop, Robert and Arel, Itamar},
booktitle = {2012 IEEE 55th International Midwest Symposium on Circuits and Systems (MWSCAS)},
doi = {10.1109/MWSCAS.2012.6292123},
keywords = {Accuracy,Biological neural networks,Feedforward neural networks,Interference,Neurons,Training,binary activations,catastrophic forgetting,catastrophic interference,fixed expansion layer feedforward neural network,multilayer perceptron,multilayer perceptrons,non-stationary inputs,sparse neurons,sparsity},
mendeley-tags = {sparsity},
month = {aug},
pages = {726--729},
title = {{Mitigation of catastrophic interference in neural networks using a fixed expansion layer}},
year = {2012}
}
@misc{Ororbia2019a,
abstract = {Temporal models based on recurrent neural networks have proven to be quite powerful in a wide variety of applications. However, training these models often relies on back-propagation through time, which entails unfolding the network over many time steps, making the process of conducting credit assignment considerably more challenging. Furthermore, the nature of back-propagation itself does not permit the use of non-differentiable activation functions and is inherently sequential, making parallelization of the underlying training process difficult. Here, we propose the Parallel Temporal Neural Coding Network (P-TNCN), a biologically inspired model trained by the learning algorithm we call Local Representation Alignment. It aims to resolve the difficulties and problems that plague recurrent networks trained by back-propagation through time. The architecture requires neither unrolling in time nor the derivatives of its internal activation functions. We compare our model and learning procedure to other back-propagation through time alternatives (which also tend to be computationally expensive), including real-time recurrent learning, echo state networks, and unbiased online recurrent optimization. We show that it outperforms these on sequence modeling benchmarks such as Bouncing MNIST, a new benchmark we denote as Bouncing NotMNIST, and Penn Treebank. Notably, our approach can in some instances outperform full back-propagation through time as well as variants such as sparse attentive back-tracking. Significantly, the hidden unit correction phase of P-TNCN allows it to adapt to new datasets even if its synaptic weights are held fixed (zero-shot adaptation) and facilitates retention of prior generative knowledge when faced with a task sequence. We present results that show the P-TNCN's ability to conduct zero-shot adaptation and online continual sequence modeling.},
annote = {Comment: Important revisions made throughout (additional items/results added, including a complexity analysis)
arXiv: 1810.07411},
author = {Ororbia, Alexander and Mali, Ankur and Giles, C Lee and Kifer, Daniel},
booktitle = {arXiv:1810.07411 [cs]},
keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,credi assignment,mnist,spiking},
mendeley-tags = {mnist,spiking},
month = {aug},
title = {{Continual Learning of Recurrent Neural Networks by Locally Aligning Distributed Representations}},
url = {http://arxiv.org/abs/1810.07411},
year = {2019}
}
