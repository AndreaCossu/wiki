@misc{Campo2020a,
abstract = {This paper proposes a method for performing continual learning of predictive models that facilitate the inference of future frames in video sequences. For a first given experience, an initial Variational Autoencoder, together with a set of fully connected neural networks are utilized to respectively learn the appearance of video frames and their dynamics at the latent space level. By employing an adapted Markov Jump Particle Filter, the proposed method recognizes new situations and integrates them as predictive models avoiding catastrophic forgetting of previously learned tasks. For evaluating the proposed method, this article uses video sequences from a vehicle that performs different tasks in a controlled environment.},
archivePrefix = {arXiv},
arxivId = {2006.01945},
author = {Campo, Damian and Slavic, Giulia and Baydoun, Mohamad and Marcenaro, Lucio and Regazzoni, Carlo},
eprint = {2006.01945},
file = {::},
keywords = {[vision]},
mendeley-tags = {[vision]},
month = {jun},
title = {{Continual Learning of Predictive Models in Video Sequences via Variational Autoencoders}},
url = {http://arxiv.org/abs/2006.01945},
year = {2020}
}
@misc{Fu2020a,
abstract = {â€  We propose an incremental learning for end-to-end Automatic Speech Recognition (ASR) to extend the model's capacity on a new task while retaining the performance on existing ones. The proposed method is effective without accessing to the old dataset to address the issues of high training cost and old dataset unavailability. To achieve this, knowledge distillation is applied as a guidance to retain the recognition ability from the previous model, which is then combined with the new ASR task for model optimization. With an ASR model pre-trained on 12,000h Mandarin speech, we test our proposed method on 300h new scenario task and 1h new named entities task. Experiments show that our method yields 3.25% and 0.88% absolute Character Error Rate (CER) reduction on the new scenario, when compared with the pre-trained model and the full-data retraining baseline, respectively. It even yields a surprising 0.37% absolute CER reduction on the new scenario than the fine-tuning. For the new named entities task, our method significantly improves the accuracy compared with the pre-trained model, i.e. 16.95% absolute CER reduction. For both of the new task adaptions, the new models still maintain a same accuracy with the baseline on the old tasks.},
author = {Fu, Li and Li, Xiaoxiao and Zi, Libo},
file = {::},
keywords = {Index Terms: automatic speech recognition,[audio],end-to-end,incremental learning,knowledge distillation},
mendeley-tags = {[audio]},
title = {{Incremental Learning for End-to-End Automatic Speech Recognition}},
year = {2020}
}
@inproceedings{sun2019a,
abstract = {Most research on lifelong learning applies to images or games, but not language. We present LAMOL, a simple yet effective method for lifelong language learning (LLL) based on language...},
author = {Sun, Fan-Keng and Ho, Cheng-Hao and Lee, Hung-Yi},
booktitle = {ICLR},
keywords = {[nlp]},
mendeley-tags = {[nlp]},
month = {sep},
shorttitle = {LAMOL},
title = {{LAMOL: LAnguage MOdeling for Lifelong Language Learning}},
url = {https://openreview.net/forum?id=Skgxcn4YDS},
year = {2020}
}
@misc{lee2018a,
abstract = {While end-to-end neural conversation models have led to promising advances in reducing hand-crafted features and errors induced by the traditional complex system architecture, they typically require an enormous amount of data due to the lack of modularity. Previous studies adopted a hybrid approach with knowledge-based components either to abstract out domain-specific information or to augment data to cover more diverse patterns. On the contrary, we propose to directly address the problem using recent developments in the space of continual learning for neural models. Specifically, we adopt a domain-independent neural conversational model and introduce a novel neural continual learning algorithm that allows a conversational agent to accumulate skills across different tasks in a data-efficient way. To the best of our knowledge, this is the first work that applies continual learning to conversation systems. We verified the efficacy of our method through a conversational skill transfer from either synthetic dialogs or human-human dialogs to human-computer conversations in a customer support domain.},
annote = {arXiv: 1712.09943},
author = {Lee, Sungjin},
booktitle = {arXiv:1712.09943 [cs]},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction,[nlp],chatbot,conversation,conversational agent,ewc,lstm},
mendeley-tags = {[nlp]},
month = {jan},
title = {{Toward Continual Learning for Conversational Agents}},
url = {http://arxiv.org/abs/1712.09943},
year = {2018}
}
@misc{kruszewski2020a,
abstract = {Continual Learning has been often framed as the problem of training a model in a sequence of tasks. In this regard, Neural Networks have been attested to forget the solutions to previous task as they learn new ones. Yet, modelling human life-long learning does not necessarily require any crisp notion of tasks. In this work, we propose a benchmark based on language modelling in a multilingual and multidomain setting that prescinds of any explicit delimitation of training examples into distinct tasks, and propose metrics to study continual learning and catastrophic forgetting in this setting. Then, we introduce a simple Product of Experts learning system that performs strongly on this problem while displaying interesting properties, and investigate its merits for avoiding forgetting.},
annote = {arXiv: 2004.03340},
author = {Kruszewski, Germ{\'{a}}n and Sorodoc, Ionut-Teodor and Mikolov, Tomas},
booktitle = {arXiv:2004.03340 [cs]},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,[nlp],expert,mixture},
mendeley-tags = {[nlp]},
month = {apr},
title = {{Class-Agnostic Continual Learning of Alternating Languages and Domains}},
url = {http://arxiv.org/abs/2004.03340},
year = {2020}
}
@article{Xue2019a,
abstract = {Recently, data-driven based Automatic Speech Recognition (ASR) systems have achieved state-of-the-art results. And transfer learning is often used when those existing systems are adapted to the target domain, e.g., fine-tuning, retraining. However, in the processes, the system parameters may well deviate too much from the previously learned parameters. Thus, it is difficult for the system training process to learn knowledge from target domains meanwhile not forgetting knowledge from the previous learning process, which is called as catastrophic forgetting (CF). In this paper, we attempt to solve the CF problem with the lifelong learning and propose a novel multi-task learning (MTL) training framework for ASR. It considers reserving original knowledge and learning new knowledge as two independent tasks, respectively. On the one hand, we constrain the new parameters not to deviate too far from the original parameters and punish the new system when forgetting original knowledge. On the other hand, we force the new system to solve new knowledge quickly. Then, a MTL mechanism is employed to get the balance between the two tasks. We applied our method to an End2End ASR task and obtained the best performance in both target and original datasets.},
archivePrefix = {arXiv},
arxivId = {1904.08039},
author = {Xue, Jiabin and Han, Jiqing and Zheng, Tieran and Gao, Xiang and Guo, Jiaxing},
eprint = {1904.08039},
keywords = {[audio],[rnn]},
mendeley-tags = {[audio],[rnn]},
title = {{A Multi-Task Learning Framework for Overcoming the Catastrophic Forgetting in Automatic Speech Recognition}},
url = {http://arxiv.org/abs/1904.08039},
year = {2019}
}
@article{Kiyasseh2020,
abstract = {Deep learning algorithms are known to experience destructive interference when instances violate the assumption of being independent and identically distributed (i.i.d). This violation, however, is ubiquitous in clinical settings where data are streamed temporally and from a multitude of physiological sensors. To overcome this obstacle, we propose CLOPS, a healthcare-specific replay-based continual learning strategy. In three continual learning scenarios based on three publically-available datasets, we show that CLOPS can outperform its multi-task learning counterpart. Moreover, we propose end-to-end trainable parameters, which we term task-instance parameters, that can be used to quantify task difficulty and similarity. This quantification yields insights into both network interpretability and clinical applications, where task difficulty is poorly quantified.},
archivePrefix = {arXiv},
arxivId = {2004.09578},
author = {Kiyasseh, Dani and Zhu, Tingting and Clifton, David A},
eprint = {2004.09578},
title = {{CLOPS: Continual Learning of Physiological Signals}},
url = {http://arxiv.org/abs/2004.09578},
year = {2020}
}
@article{Bapna2019a,
abstract = {Neural Networks trained with gradient descent are known to be susceptible to catastrophic forgetting caused by parameter shift during the training process. In the context of Neural Machine Translation (NMT) this results in poor performance on heterogeneous datasets and on sub-tasks like rare phrase translation. On the other hand, non-parametric approaches are immune to forgetting, perfectly complementing the generalization ability of NMT. However, attempts to combine non-parametric or retrieval based approaches with NMT have only been successful on narrow domains, possibly due to over-reliance on sentence level retrieval. We propose a novel n-gram level retrieval approach that relies on local phrase level similarities, allowing us to retrieve neighbors that are useful for translation even when overall sentence similarity is low. We complement this with an expressive neural network, allowing our model to extract information from the noisy retrieved context. We evaluate our semi-parametric NMT approach on a heterogeneous dataset composed of WMT, IWSLT, JRC-Acquis and OpenSubtitles, and demonstrate gains on all 4 evaluation sets. The semi-parametric nature of our approach opens the door for non-parametric domain adaptation, demonstrating strong inference-time adaptation performance on new domains without the need for any parameter updates.},
archivePrefix = {arXiv},
arxivId = {1903.00058},
author = {Bapna, Ankur and Firat, Orhan},
eprint = {1903.00058},
keywords = {[nlp]},
mendeley-tags = {[nlp]},
title = {{Non-Parametric Adaptation for Neural Machine Translation}},
url = {http://arxiv.org/abs/1903.00058},
year = {2019}
}
