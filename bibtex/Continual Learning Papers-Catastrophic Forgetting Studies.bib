@inproceedings{davidson2020a,
abstract = {We explore the behavior of a standard convolutional neural net in a continual-learning setting that introduces visual classification tasks sequentially and requires the net to master new tasks while preserving mastery of previously learned tasks. This setting corresponds to that which human learners face as they acquire domain expertise serially, for example, as an individual studies a textbook. Through simulations involving sequences of ten related visual tasks, we find reason for optimism that nets will scale well as they advance from having a single skill to becoming multi-skill domain experts. We observe two key phenomena. First, forward facilitation-the accelerated learning of task n+1 having learned n previous tasks-grows with n. Second, backward interference-the forgetting of the n previous tasks when learning task n + 1-diminishes with n. Amplifying forward facilitation is the goal of research on metalearning, and attenuating backward interference is the goal of research on catastrophic forgetting. We find that both of these goals are attained simply through broader exposure to a domain.},
author = {Davidson, Guy and Mozer, Michael C},
booktitle = {CVPR},
file = {::},
keywords = {[vision]},
mendeley-tags = {[vision]},
pages = {9282--9293},
title = {{Sequential mastery of multiple visual tasks: Networks naturally learn to learn and forget to forget}},
url = {https://openaccess.thecvf.com/content{\_}CVPR{\_}2020/papers/Davidson{\_}Sequential{\_}Mastery{\_}of{\_}Multiple{\_}Visual{\_}Tasks{\_}Networks{\_}Naturally{\_}Learn{\_}to{\_}CVPR{\_}2020{\_}paper.pdf},
year = {2020}
}
@article{Nguyen2019a,
abstract = {We study the relationship between catastrophic forgetting and properties of task sequences. In particular, given a sequence of tasks, we would like to understand which properties of this sequence influence the error rates of continual learning algorithms trained on the sequence. To this end, we propose a new procedure that makes use of recent developments in task space modeling as well as correlation analysis to specify and analyze the properties we are interested in. As an application, we apply our procedure to study two properties of a task sequence: (1) total complexity and (2) sequential heterogeneity. We show that error rates are strongly and positively correlated to a task sequence's total complexity for some state-of-the-art algorithms. We also show that, surprisingly, the error rates have no or even negative correlations in some cases to sequential heterogeneity. Our findings suggest directions for improving continual learning benchmarks and methods.},
archivePrefix = {arXiv},
arxivId = {1908.01091},
author = {Nguyen, Cuong V and Achille, Alessandro and Lam, Michael and Hassner, Tal and Mahadevan, Vijay and Soatto, Stefano},
eprint = {1908.01091},
journal = {arXiv},
keywords = {[cifar],[mnist]},
mendeley-tags = {[cifar],[mnist]},
month = {aug},
title = {{Toward Understanding Catastrophic Forgetting in Continual Learning}},
url = {http://arxiv.org/abs/1908.01091},
year = {2019}
}
@article{Mermillod2013,
author = {Mermillod, Martial and Bugaiska, Aur{\'{e}}lia and Bonin, Patrick},
doi = {10.3389/fpsyg.2013.00504},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Mermillod2013a},
number = {August},
pages = {504},
pmid = {23935590},
title = {{The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3732997{\%}7B{\%}5C{\&}{\%}7Dtool=pmcentrez{\%}7B{\%}5C{\&}{\%}7Drendertype=abstract http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00504/abstract},
volume = {4},
year = {2013}
}
@article{Wiewel2019a,
abstract = {Artificial neural networks (ANNs) suffer from catastrophic forgetting when trained on a sequence of tasks. While this phenomenon was studied in the past, there is only very limited recent research on this phenomenon. We propose a method for determining the contribution of individual parameters in an ANN to catastrophic forgetting. The method is used to analyze an ANNs response to three different continual learning scenarios.},
archivePrefix = {arXiv},
arxivId = {1906.02568},
author = {Wiewel, Felix and Yang, Bin},
eprint = {1906.02568},
journal = {arXiv},
keywords = {[mnist]},
mendeley-tags = {[mnist]},
title = {{Localizing Catastrophic Forgetting in Neural Networks}},
url = {http://arxiv.org/abs/1906.02568},
year = {2019}
}
@article{Nguyen2020a,
abstract = {Interpreting the behaviors of Deep Neural Networks (usually considered as a black box) is critical especially when they are now being widely adopted over diverse aspects of human life. Taking the advancements from Explainable Artificial Intelligent, this paper proposes a novel technique called Auto DeepVis to dissect catastrophic forgetting in continual learning. A new method to deal with catastrophic forgetting named critical freezing is also introduced upon investigating the dilemma by Auto DeepVis. Experiments on a captioning model meticulously present how catastrophic forgetting happens, particularly showing which components are forgetting or changing. The effectiveness of our technique is then assessed; and more precisely, critical freezing claims the best performance on both previous and coming tasks over baselines, proving the capability of the investigation. Our techniques could not only be supplementary to existing solutions for completely eradicating catastrophic forgetting for life-long learning but also explainable.},
archivePrefix = {arXiv},
arxivId = {2001.01578},
author = {Nguyen, Giang and Chen, Shuan and Do, Thao and Jun, Tae Joon and Choi, Ho-Jin and Kim, Daeyoung},
eprint = {2001.01578},
journal = {arXiv},
keywords = {[vision]},
mendeley-tags = {[vision]},
title = {{Dissecting Catastrophic Forgetting in Continual Learning by Deep Visualization}},
url = {http://arxiv.org/abs/2001.01578},
year = {2020}
}
@inproceedings{Pfulb2018a,
abstract = {We present a large-scale empirical study of catastrophic forgetting (CF) in modern Deep Neural Network (DNN) models that perform sequential (or: incremen-tal) learning. A new experimental protocol is proposed that enforces typical constraints encountered in application scenarios. As the investigation is empirical, we evaluate CF behavior on the hitherto largest number of visual classification datasets, from each of which we construct a representative number of Sequential Learning Tasks (SLTs) in close alignment to previous works on CF. Our results clearly indicate that there is no model that avoids CF for all investigated datasets and SLTs under application conditions. We conclude with a discussion of potential solutions and workarounds to CF, notably for the EWC and IMM models.},
author = {Pf{\"{u}}lb, B and Gepperth, A},
booktitle = {ICLR},
file = {::},
keywords = {[fashion],[mnist]},
mendeley-tags = {[fashion],[mnist]},
month = {sep},
title = {{A comprehensive, application-oriented study of catastrophic forgetting in DNNs}},
url = {https://openreview.net/pdf?id=BkloRs0qK7},
year = {2018}
}
@article{Robins1995a,
abstract = {This paper reviews the problem of catastrophic forgetting (the loss or disruption of previously learned information when new information is learned) in neural networks, and explores rehearsal mechanisms (the retraining of some of the previously learned information as the new information is added) as a potential solution. W e replicate some of the experiments described by Ratcliff (1990), including those relating to a simple `recency' based rehearsal regime. We then develop further rehearsal regimes which are more effective than recency rehearsal. In particular, `sweep rehearsal' is very successful at minimizing catastrophic forgetting. One possible limitation of rehearsal in general, however, is that previously learned information may not be available for retraining. W e describe a solution to this problem, `pseudorehearsal' , a method which provides the advantages of rehearsal without actually requiring any access to the previously learned information (the original training population) itself. We then suggest an interpretation of these rehearsal mechanisms in the context of a function approximation based account of neural network learning. Both rehearsal and pseudorehearsal may have practical applications, allowing new information to be integrated into an existing network with minimum disruption of old informa tion.},
annote = {An in-depth overview of rehearsal techniques, including pseudo-rehearsal. Useful to combine these ideas in dual systems, in which one system learns a task while the other provides rehearsal of previous patterns.},
author = {Robins, Anthony},
doi = {10.1080/09540099550039318},
issn = {0954-0091, 1360-0494},
journal = {Connection Science},
keywords = {[dual]},
language = {en},
mendeley-tags = {[dual]},
month = {jun},
number = {2},
pages = {123--146},
title = {{Catastrophic Forgetting; Catastrophic Interference; Stability; Plasticity; Rehearsal.}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09540099550039318},
volume = {7},
year = {1995}
}
@inproceedings{Kemker2018a,
abstract = {Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task, e.g., bird classification, it cannot easily be trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than re-training the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization, ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on real-world images and sounds show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem is not yet solved.},
author = {Kemker, Ronald and McClure, Marc and Abitino, Angelina and Hayes, Tyler L and Kanan, Christopher},
booktitle = {Thirty-Second AAAI Conference on Artificial Intelligence},
keywords = {[mnist],audioset,kemker,review,survey},
language = {en},
mendeley-tags = {[mnist]},
month = {apr},
title = {{Measuring Catastrophic Forgetting in Neural Networks}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16410},
year = {2018}
}
@article{French1999a,
author = {French, Robert},
doi = {10.1016/S1364-6613(99)01294-2},
issn = {1364-6613, 1879-307X},
journal = {Trends in Cognitive Sciences},
keywords = {Catastrophic forgetting,Connectionism,Connectionist networks,Interference,Learning,Memory,Neuroscience,[sparsity],biology},
language = {English},
mendeley-tags = {[sparsity]},
month = {apr},
number = {4},
pages = {128--135},
pmid = {10322466},
title = {{Catastrophic forgetting in connectionist networks}},
url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(99)01294-2},
volume = {3},
year = {1999}
}
@article{Diaz-Rodriguez2018a,
abstract = {Continual learning consists of algorithms that learn from a stream of data/tasks continuously and adaptively thought time, enabling the incremental development of ever more complex knowledge and skills. The lack of consensus in evaluating continual learning algorithms and the almost exclusive focus on forgetting motivate us to propose a more comprehensive set of implementation independent metrics accounting for several factors we believe have practical implications worth considering in the deployment of real AI systems that learn continually: accuracy or performance over time, backward and forward knowledge transfer, memory overhead as well as computational efficiency. Drawing inspiration from the standard Multi-Attribute Value Theory (MAVT) we further propose to fuse these metrics into a single score for ranking purposes and we evaluate our proposal with five continual learning strategies on the iCIFAR-100 continual learning benchmark.},
annote = {arXiv: 1810.13166},
author = {D{\'{i}}az-Rodr{\'{i}}guez, Natalia and Lomonaco, Vincenzo and Filliat, David and Maltoni, Davide},
journal = {arXiv},
keywords = {68T05,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,[cifar],[framework],cs.AI,cs.CV,cs.LG,cs.NE,stat.ML},
mendeley-tags = {[cifar],[framework]},
month = {oct},
shorttitle = {Don't forget, there is more than forgetting},
title = {{Don't forget, there is more than forgetting: new metrics for Continual Learning}},
url = {http://arxiv.org/abs/1810.13166},
year = {2018}
}
@inproceedings{Toneva2018a,
abstract = {Inspired by the phenomenon of catastrophic forgetting, we investigate the learning dynamics of neural networks as they train on single classification tasks. Our goal is to understand whether a...},
annote = {An interesting aspect of this paper is related to the study of unforgettable patterns and how they influence performance in terms of forgetting.},
author = {Toneva, Mariya and Sordoni, Alessandro and des Combes, Remi Tachet and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
booktitle = {International Conference on Learning Representations},
keywords = {[cifar],[mnist]},
mendeley-tags = {[cifar],[mnist]},
month = {sep},
title = {{An Empirical Study of Example Forgetting during Deep Neural Network Learning}},
url = {https://openreview.net/forum?id=BJlxm30cKm},
year = {2019}
}
