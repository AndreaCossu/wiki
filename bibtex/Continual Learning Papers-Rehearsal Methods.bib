@article{Zhang2019a,
abstract = {Continual learning is a critical ability of continually acquiring and transferring knowledge without catastrophically forgetting previously learned knowledge. However, enabling continual learning for AI remains a long-standing challenge. In this work, we propose a novel method, Prototype Reminding, that efficiently embeds and recalls previously learnt knowledge to tackle catastrophic forgetting issue. In particular, we consider continual learning in classification tasks. For each classification task, our method learns a metric space containing a set of prototypes where embedding of the samples from the same class cluster around prototypes and class-representative prototypes are separated apart. To alleviate catastrophic forgetting, our method preserves the embedding function from the samples to the previous metric space, through our proposed prototype reminding from previous tasks. Specifically, the reminding process is implemented by replaying a small number of samples from previous tasks and correspondingly matching their embedding to their nearest class-representative prototypes. Compared with recent continual learning methods, our contributions are fourfold: first, our method achieves the best memory retention capability while adapting quickly to new tasks. Second, our method uses metric learning for classification, and does not require adding in new neurons given new object classes. Third, our method is more memory efficient since only class-representative prototypes need to be recalled. Fourth, our method suggests a promising solution for few-shot continual learning. Without tampering with the performance on initial tasks, our method learns novel concepts given a few training examples of each class in new tasks.},
archivePrefix = {arXiv},
arxivId = {1905.09447},
author = {Zhang, Mengmi and Wang, Tao and Lim, Joo Hwee and Feng, Jiashi},
eprint = {1905.09447},
journal = {arXiv},
keywords = {[bayes],[cifar],[imagenet],[mnist]},
mendeley-tags = {[bayes],[cifar],[imagenet],[mnist]},
pages = {1--10},
title = {{Prototype Reminding for Continual Learning}},
url = {http://arxiv.org/abs/1905.09447},
year = {2019}
}
@article{Isele2018a,
abstract = {Deep reinforcement learning has emerged as a powerful tool for a variety of learning tasks, however deep nets typically exhibit forgetting when learning multiple tasks in sequence. To mitigate forgetting, we propose an experience replay process that augments the standard FIFO buffer and selectively stores experiences in a long-term memory. We explore four strategies for selecting which experiences will be stored: favoring surprise, favoring reward, matching the global training distribution, and maximizing coverage of the state space. We show that distribution matching successfully prevents catastrophic forgetting, and is consistently the best approach on all domains tested. While distribution matching has better and more consistent performance, we identify one case in which coverage maximization is beneficial - when tasks that receive less trained are more important. Overall, our results show that selective experience replay, when suitable selection algorithms are employed, can prevent catastrophic forgetting.},
archivePrefix = {arXiv},
arxivId = {1802.10269},
author = {Isele, David and Cosgun, Akansel},
eprint = {1802.10269},
journal = {Thirty-Second AAAI Conference on Artificial Intelligence},
keywords = {Natural Language Processing and Machine Learning T},
month = {feb},
pages = {3302--3309},
title = {{Selective Experience Replay for Lifelong Learning}},
url = {http://arxiv.org/abs/1802.10269},
year = {2018}
}
@article{Chen2018a,
abstract = {Continual learning aims to enable machine learning models to learn a general solution space for past and future tasks in a sequential manner. Conventional models tend to forget the knowledge of previous tasks while learning a new task, a phenomenon known as catastrophic forgetting. When using Bayesian models in continual learning, knowledge from previous tasks can be retained in two ways: 1). posterior distributions over the parameters, containing the knowledge gained from inference in previous tasks, which then serve as the priors for the following task; 2). coresets, containing knowledge of data distributions of previous tasks. Here, we show that Bayesian continual learning can be facilitated in terms of these two means through the use of natural gradients and Stein gradients respectively.},
archivePrefix = {arXiv},
arxivId = {1904.10644},
author = {Chen, Yu and Diethe, Tom and Lawrence, Neil},
eprint = {1904.10644},
journal = {arXiv},
keywords = {[bayes]},
mendeley-tags = {[bayes]},
month = {apr},
title = {{Facilitating Bayesian Continual Learning by Natural Gradients and Stein Gradients}},
url = {http://arxiv.org/abs/1904.10644},
year = {2019}
}
@inproceedings{rolnick2019a,
abstract = {Interacting with a complex world involves continual learning, in which tasks and data distributions change over time. A continual learning system should demonstrate both plasticity (acquisition of new knowledge) and stability (preservation of old knowledge). Catastrophic forgetting is the failure of stability, in which new experience overwrites previous experience. In the brain, replay of past experience is widely believed to reduce forgetting, yet it has been largely overlooked as a solution to forgetting in deep reinforcement learning. Here, we introduce CLEAR, a replay-based method that greatly reduces catastrophic forgetting in multi-task reinforcement learning. CLEAR leverages off-policy learning and behavioral cloning from replay to enhance stability, as well as on-policy learning to preserve plasticity. We show that CLEAR performs better than state-of-the-art deep learning techniques for mitigating forgetting, despite being significantly less complicated and not requiring any knowledge of the individual tasks being learned.},
author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy P and Wayne, Greg},
booktitle = {NeurIPS},
file = {::},
pages = {350--360},
title = {{Experience Replay for Continual Learning}},
url = {http://papers.nips.cc/paper/8327-experience-replay-for-continual-learning.pdf},
year = {2019}
}
@article{Arumae2020a,
abstract = {Training large language representation models has become a standard in the natural language processing community. This allows for fine tuning on any number of specific tasks, however, these large high capacity models can continue to train on domain specific unlabeled data to make initialization even more robust for supervised tasks. We demonstrate that in practice these pre-trained models present performance deterioration in the form of catastrophic forgetting when evaluated on tasks from a general domain such as GLUE. In this work we propose CALM, Continuous Adaptive Learning for Language Modeling: techniques to render models which retain knowledge across multiple domains. With these methods, we are able to reduce the performance gap across supervised tasks introduced by task specific models which we demonstrate using a continual learning setting in biomedical and clinical domains.},
archivePrefix = {arXiv},
arxivId = {2004.03794},
author = {Arumae, Kristjan and Bhatia, Parminder},
eprint = {2004.03794},
journal = {arXiv},
keywords = {[nlp]},
mendeley-tags = {[nlp]},
title = {{CALM: Continuous Adaptive Learning for Language Modeling}},
url = {http://arxiv.org/abs/2004.03794},
year = {2020}
}
@article{Kiyasseh2020,
abstract = {Deep learning algorithms are known to experience destructive interference when instances violate the assumption of being independent and identically distributed (i.i.d). This violation, however, is ubiquitous in clinical settings where data are streamed temporally and from a multitude of physiological sensors. To overcome this obstacle, we propose CLOPS, a healthcare-specific replay-based continual learning strategy. In three continual learning scenarios based on three publically-available datasets, we show that CLOPS can outperform its multi-task learning counterpart. Moreover, we propose end-to-end trainable parameters, which we term task-instance parameters, that can be used to quantify task difficulty and similarity. This quantification yields insights into both network interpretability and clinical applications, where task difficulty is poorly quantified.},
archivePrefix = {arXiv},
arxivId = {2004.09578},
author = {Kiyasseh, Dani and Zhu, Tingting and Clifton, David A},
eprint = {2004.09578},
journal = {arXiv},
title = {{CLOPS: Continual Learning of Physiological Signals}},
url = {http://arxiv.org/abs/2004.09578},
year = {2020}
}
@inproceedings{Oswal2019a,
abstract = {Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned...},
author = {von Oswald, Johannes and Henning, Christian and Sacramento, Jo{\~{a}}o and Grewe, Benjamin F},
booktitle = {International Conference on Learning Representations},
keywords = {[cifar],[mnist]},
mendeley-tags = {[cifar],[mnist]},
month = {sep},
title = {{Continual learning with hypernetworks}},
url = {https://openreview.net/forum?id=SJgwNerKvB},
year = {2020}
}
@inproceedings{Aljundi2019a,
author = {Aljundi, Rahaf and Belilovsky, Eugene and Tuytelaars, Tinne and Charlin, Laurent and Caccia, Massimo and Lin, Min and Page-Caccia, Lucas},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d$\backslash$textquotesingle Alch{\'{e}}-Buc, F and Fox, E and Garnett, R},
keywords = {[cifar],[mnist]},
mendeley-tags = {[cifar],[mnist]},
pages = {11849--11860},
publisher = {Curran Associates, Inc.},
title = {{Online Continual Learning with Maximal Interfered Retrieval}},
url = {http://papers.nips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval.pdf},
year = {2019}
}
