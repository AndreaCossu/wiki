
@article{antoniou2020,
  title = {Defining {{Benchmarks}} for {{Continual Few}}-{{Shot Learning}}},
  author = {Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos},
  year = {2020},
  month = apr,
  url = {http://arxiv.org/abs/2004.11967},
  abstract = {Both few-shot and continual learning have seen substantial progress in the last years due to the introduction of proper benchmarks. That being said, the field has still to frame a suite of benchmarks for the highly desirable setting of continual few-shot learning, where the learner is presented a number of few-shot tasks, one after the other, and then asked to perform well on a validation set stemming from all previously seen tasks. Continual few-shot learning has a small computational footprint and is thus an excellent setting for efficient investigation and experimentation. In this paper we first define a theoretical framework for continual few-shot learning, taking into account recent literature, then we propose a range of flexible benchmarks that unify the evaluation criteria and allows exploring the problem from multiple perspectives. As part of the benchmark, we introduce a compact variant of ImageNet, called SlimageNet64, which retains all original 1000 classes but only contains 200 instances of each one (a total of 200K data-points) downscaled to 64 x 64 pixels. We provide baselines for the proposed benchmarks using a number of popular few-shot learning algorithms, as a result, exposing previously unknown strengths and weaknesses of those algorithms in continual and data-limited settings.},
  annotation = {\_eprint: 2004.11967},
  journal = {arXiv},
  keywords = {[imagenet]}
}

@inproceedings{lomonaco2017,
  title = {{{CORe50}}: A {{New Dataset}} and {{Benchmark}} for {{Continuous Object Recognition}}},
  booktitle = {Proceedings of the 1st {{Annual Conference}} on {{Robot Learning}}},
  author = {Lomonaco, Vincenzo and Maltoni, Davide},
  editor = {Levine, Sergey and Vanhoucke, Vincent and Goldberg, Ken},
  year = {2017},
  month = may,
  volume = {78},
  pages = {17--26},
  publisher = {{PMLR}},
  url = {http://proceedings.mlr.press/v78/lomonaco17a.html},
  abstract = {Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while na\"ive incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios.},
  keywords = {[vision]},
  series = {Proceedings of {{Machine Learning Research}}}
}

@inproceedings{lomonaco2020,
  title = {Continual {{Reinforcement Learning}} in {{3D Non}}-{{Stationary Environments}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  author = {Lomonaco, Vincenzo and Desai, Karan and Culurciello, Eugenio and Maltoni, Davide},
  year = {2020},
  pages = {248--249},
  url = {https://openaccess.thecvf.com/content_CVPRW_2020/html/w15/Lomonaco_Continual_Reinforcement_Learning_in_3D_Non-Stationary_Environments_CVPRW_2020_paper.html},
  abstract = {High-dimensional always-changing environments constitute a hard challenge for current reinforcement learning techniques. Artificial agents, nowadays, are often trained off-line in very static and controlled conditions in simulation such that training observations can be thought as sampled i.i.d. from the entire observations space. However, in real world settings, the environment is often non-stationary and subject to unpredictable, frequent changes. In this paper we propose and openly release CRLMaze, a new benchmark for learning continually through reinforcement in a complex 3D non-stationary task based on ViZDoom and subject to several environmental changes. Then, we introduce an end-to-end model-free continual reinforcement learning strategy showing competitive results with respect to four different baselines and not requiring any access to additional supervised signals, previously encountered environmental conditions or observations.}
}

@article{she2019,
  title = {{{OpenLORIS}}-{{Object}}: {{A Robotic Vision Dataset}} and {{Benchmark}} for {{Lifelong Deep Learning}}},
  author = {She, Qi and Feng, Fan and Hao, Xinyue and Yang, Qihan and Lan, Chuanlin and Lomonaco, Vincenzo and Shi, Xuesong and Wang, Zhengwei and Guo, Yao and Zhang, Yimin and Qiao, Fei and Chan, Rosa H M},
  year = {2019},
  month = nov,
  pages = {1--8},
  url = {http://arxiv.org/abs/1911.06487},
  abstract = {The recent breakthroughs in computer vision have benefited from the availability of large representative datasets (e.g. ImageNet and COCO) for training. Yet, robotic vision poses unique challenges for applying visual algorithms developed from these standard computer vision datasets due to their implicit assumption over non-varying distributions for a fixed set of tasks. Fully retraining models each time a new task becomes available is infeasible due to computational, storage and sometimes privacy issues, while na\$\textbackslash backslash\$"\{i\}ve incremental strategies have been shown to suffer from catastrophic forgetting. It is crucial for the robots to operate continuously under open-set and detrimental conditions with adaptive visual perceptual systems, where lifelong learning is a fundamental capability. However, very few datasets and benchmarks are available to evaluate and compare emerging techniques. To fill this gap, we provide a new lifelong robotic vision dataset ("OpenLORIS-Object") collected via RGB-D cameras. The dataset embeds the challenges faced by a robot in the real-life application and provides new benchmarks for validating lifelong object recognition algorithms. Moreover, we have provided a testbed of \$9\$ state-of-the-art lifelong learning algorithms. Each of them involves \$48\$ tasks with \$4\$ evaluation metrics over the OpenLORIS-Object dataset. The results demonstrate that the object recognition task in the ever-changing difficulty environments is far from being solved and the bottlenecks are at the forward/backward transfer designs. Our dataset and benchmark are publicly available at at \$\textbackslash backslash\$href\{https://lifelong-robotic-vision.github.io/dataset/object\}\{\$\textbackslash backslash\$underline\{https://lifelong-robotic-vision.github.io/dataset/object\}\}.},
  annotation = {\_eprint: 1911.06487},
  journal = {arXiv},
  keywords = {[vision]}
}


