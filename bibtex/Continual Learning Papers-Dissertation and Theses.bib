@phdthesis{lomonaco2019a,
abstract = {Humans have the extraordinary ability to learn continually from experience. Not only we can apply previously learned knowledge and skills to new situations, we can also use these as the foundation for later learning. One of the grand goals of Artificial Intelligence (AI) is building an artificial “continual learning” agent that constructs a sophisticated understanding of the world from its own experience through the autonomous incremental development of ever more complex knowledge and skills. However, despite early speculations and few pioneering works, very little research and effort has been devoted to address this vision. Current AI systems greatly suffer from the exposure to new data or environments which even slightly differ from the ones for which they have been trained for. Moreover, the learning process is usually constrained on fixed datasets within narrow and isolated tasks which may hardly lead to the emergence of more complex and autonomous intelligent behaviors. In essence, continual learning and adaptation capabilities, while more than often thought as fundamental pillars of every intelligent agent, have been mostly left out of the main AI research focus. In this dissertation, we study the application of these ideas in light of the more recent advances in machine learning research and in the context of deep architectures for AI. We propose a comprehensive and unifying framework for continual learning, new metrics, benchmarks and algorithms, as well as providing substantial experimental evaluations in different supervised, unsupervised and reinforcement learning tasks.},
author = {Lomonaco, Vincenzo},
doi = {Lomonaco, Vincenzo (2019) Continual Learning with Deep Architectures, [Dissertation thesis], Alma Mater Studiorum Università di Bologna. Dottorato di ricerca in Computer science and engineering <http://amsdottorato.unibo.it/view/dottorati/DOT536/>, 31 Ciclo. DOI 10.6092/unibo/amsdottorato/9073.},
keywords = {[framework]},
language = {it},
mendeley-tags = {[framework]},
month = {apr},
school = {alma},
title = {{Continual Learning with Deep Architectures}},
url = {http://amsdottorato.unibo.it/9073/},
year = {2019}
}
@article{Grosmann2001b,
abstract = {Autonomous mobile robots should be able to learn incrementally and adapt to changes in the operating environment during their entire lifetime. This is referred to as continual learning. In this thesis, I propose an approach to continual learning which is based on adaptive state-space quantisation and reinforcement learning. Representational tools for continual learning should be constructive, as the learning task is not known a priori, and allow the transfer of information between related tasks. The proposed learning method uses constructive neural networks and instance-based learning to compute a task-dependent agent-internal state space that can be adapted to new learning tasks easily. The continual learning method has been applied to a mobile robot that had to learn navigation tasks in different environments. This scenario is challenging as the performance feedback is sparse and the interaction with the environment is non-deterministic. I provide a performance comparison of model-based and model-free reinforcement learning algorithms for the robot navigation task and evaluate the capability of the learning system to adapt to changes in the operating environment. Although only experiments dealing with change to the environment are reported, the methods developed in the thesis are intended for more general multi-task-learning. It is hoped that the learning method will lead to a speed-up in applications of reinforcement learning and enable an autonomous robot to adapt its behaviour during its entire lifetime.},
author = {Gro{\ss}mann, Axel},
number = {February},
title = {{Continual Learning for Mobile Robots}},
year = {2001}
}
