@article{ayub2020b,
abstract = {The two main challenges faced by continual learning approaches are catastrophic forgetting and memory limitations on the storage of data. To cope with these challenges, we propose a novel, cognitively-inspired approach which trains autoencoders with Neural Style Transfer to encode and store images. Reconstructed images from encoded episodes are replayed when training the classifier model on a new task to avoid catastrophic forgetting. The loss function for the reconstructed images is weighted to reduce its effect during classifier training to cope with image degradation. When the system runs out of memory the encoded episodes are converted into centroids and covariance matrices, which are used to generate pseudo-images during classifier training, keeping classifier performance stable with less memory. Our approach increases classification accuracy by 13-17{\%} over state-of-the-art methods on benchmark datasets, while requiring 78{\%} less storage space.},
archivePrefix = {arXiv},
arxivId = {2007.06637},
author = {Ayub, Ali and Wagner, Alan R.},
eprint = {2007.06637},
journal = {arXiv},
keywords = {[generative],[imagenet],[mnist],catastrophic forgetting,continual learning},
mendeley-tags = {[generative],[imagenet],[mnist]},
month = {jun},
title = {{Storing Encoded Episodes as Concepts for Continual Learning}},
url = {https://arxiv.org/abs/2007.06637 http://arxiv.org/abs/2007.06637},
year = {2020}
}
@article{Rostami2019a,
abstract = {Despite huge success, deep networks are unable to learn effectively in sequential multitask learning settings as they forget the past learned tasks after learning new tasks. Inspired from complementary learning systems theory, we address this challenge by learning a generative model that couples the current task to the past learned tasks through a discriminative embedding space. We learn an abstract level generative distribution in the embedding that allows the generation of data points to represent the experience. We sample from this distribution and utilize experience replay to avoid forgetting and simultaneously accumulate new knowledge to the abstract distribution in order to couple the current task with past experience. We demonstrate theoretically and empirically that our framework learns a distribution in the embedding that is shared across all task and as a result tackles catastrophic forgetting.},
archivePrefix = {arXiv},
arxivId = {1903.04566},
author = {Rostami, Mohammad and Kolouri, Soheil and Pilly, Praveen K},
eprint = {1903.04566},
journal = {arXiv},
month = {mar},
title = {{Complementary Learning for Overcoming Catastrophic Forgetting Using Experience Replay}},
url = {http://arxiv.org/abs/1903.04566},
year = {2019}
}
@article{Wang2019a,
abstract = {Continual learning consists in incrementally training a model on a sequence of datasets and testing on the union of all datasets. In this paper, we examine continual learning for the problem of sound classification, in which we wish to refine already trained models to learn new sound classes. In practice one does not want to maintain all past training data and retrain from scratch, but naively updating a model with new data(sets) results in a degradation of already learned tasks, which is referred to as "catastrophic forgetting." We develop a generative replay procedure for generating training audio spectrogram data, in place of keeping older training datasets. We show that by incrementally refining a classifier with generative replay a generator that is 4{\%} of the size of all previous training data matches the performance of refining the classifier keeping 20{\%} of all previous training data. We thus conclude that we can extend a trained sound classifier to learn new classes without having to keep previously used datasets.},
annote = {arXiv: 1906.00654},
author = {Wang, Zhepei and Subakan, Cem and Tzinis, Efthymios and Smaragdis, Paris and Charlin, Laurent},
journal = {arXiv},
keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio,Statistics - Machine Learning,[audio],audio,sequence,sequences,time series},
mendeley-tags = {[audio]},
month = {jun},
title = {{Continual Learning of New Sound Classes using Generative Replay}},
url = {http://arxiv.org/abs/1906.00654},
year = {2019}
}
@inproceedings{Shin2017a,
author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
keywords = {[mnist]},
mendeley-tags = {[mnist]},
pages = {2990--2999},
publisher = {Curran Associates, Inc.},
title = {{Continual Learning with Deep Generative Replay}},
url = {http://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay.pdf},
year = {2017}
}
@article{Parisi2018a,
abstract = {Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting in which novel sensory experience interferes with existing representations and leads to abrupt decreases in the performance on previously acquired knowledge. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. Therefore, specialized neural network mechanisms are required that adapt to novel sequential experience while preventing disruptive interference with existing representations. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios.},
author = {Parisi, German I and Tani, Jun and Weber, Cornelius and Wermter, Stefan},
doi = {10.3389/fnbot.2018.00078},
issn = {1662-5218},
journal = {Frontiers in Neurorobotics},
keywords = {CLS,Incremental Learning,Lifelong learning,Memory,Self-organizing Network,[core50],[dual],[som],object recognition systems},
language = {English},
mendeley-tags = {[core50],[dual],[som]},
title = {{Lifelong Learning of Spatiotemporal Representations With Dual-Memory Recurrent Self-Organization}},
url = {https://www.frontiersin.org/articles/10.3389/fnbot.2018.00078/full},
volume = {12},
year = {2018}
}
